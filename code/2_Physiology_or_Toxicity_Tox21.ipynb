{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/__init__.py:747: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:431.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(8) # for reproduce\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  7831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:10:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:10:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:10:46] Explicit valence for atom # 8 Al, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not successfully processed smiles:  NC(=O)NC1N=C(O[AlH3](O)O)NC1=O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:10:46] Explicit valence for atom # 3 Al, 6, is greater than permitted\n",
      "[01:10:46] Explicit valence for atom # 4 Al, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not successfully processed smiles:  O=CO[AlH3](OC=O)OC=O\n",
      "not successfully processed smiles:  CC(=O)O[AlH3](O)O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:10:46] Explicit valence for atom # 4 Al, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not successfully processed smiles:  CC(=O)O[AlH3](O)OC(C)=O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:10:47] Explicit valence for atom # 9 Al, 6, is greater than permitted\n",
      "[01:10:47] Explicit valence for atom # 5 Al, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not successfully processed smiles:  CCOC(=O)/C=C(/C)O[AlH3](OC(C)CC)OC(C)CC\n",
      "not successfully processed smiles:  CCCCO[AlH3](OCCCC)OCCCC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:10:47] Explicit valence for atom # 16 Al, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not successfully processed smiles:  O=S(=O)(OC[C@H]1O[C@H](O[C@]2(COS(=O)(=O)O[AlH3](O)O)O[C@H](COS(=O)(=O)O[AlH3](O)O)[C@@H](OS(=O)(=O)O[AlH3](O)O)[C@@H]2OS(=O)(=O)O[AlH3](O)O)[C@H](OS(=O)(=O)O[AlH3](O)O)[C@@H](OS(=O)(=O)O[AlH3](O)O)[C@@H]1OS(=O)(=O)O[AlH3](O)O)O[AlH3](O)O.O[AlH3](O)[AlH3](O)O.O[AlH3](O)[AlH3](O)O.O[AlH3](O)[AlH3](O)O.O[AlH3](O)[AlH3](O)O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:10:47] Explicit valence for atom # 20 Al, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not successfully processed smiles:  CCCCCCCCCCCCCCCCCC(=O)O[AlH3](O)O\n",
      "number of successfully processed smiles:  7823\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'tox21'\n",
    "tasks = [\n",
    "  'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD',\n",
    "  'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n",
    "]\n",
    "raw_filename = \"../data/tox21.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.histplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(len([i for i in atom_num_dist if i<51]),len([i for i in atom_num_dist if i>50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 888\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 800\n",
    "p_dropout = 0.5\n",
    "fingerprint_dim = 200\n",
    "\n",
    "radius = 3\n",
    "T = 3\n",
    "weight_decay = 3 \n",
    "learning_rate = 3.5\n",
    "per_task_output_units_num = 2 \n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR-AR</th>\n",
       "      <th>NR-AR-LBD</th>\n",
       "      <th>NR-AhR</th>\n",
       "      <th>NR-Aromatase</th>\n",
       "      <th>NR-ER</th>\n",
       "      <th>NR-ER-LBD</th>\n",
       "      <th>NR-PPAR-gamma</th>\n",
       "      <th>SR-ARE</th>\n",
       "      <th>SR-ATAD5</th>\n",
       "      <th>SR-HSE</th>\n",
       "      <th>SR-MMP</th>\n",
       "      <th>SR-p53</th>\n",
       "      <th>mol_id</th>\n",
       "      <th>smiles</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX14836</td>\n",
       "      <td>[I-].[K+]</td>\n",
       "      <td>[I-].[K+]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TOX811</td>\n",
       "      <td>[Hg+2]</td>\n",
       "      <td>[Hg+2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX131</td>\n",
       "      <td>[Ba+2]</td>\n",
       "      <td>[Ba+2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOX4331</td>\n",
       "      <td>[TlH2+]</td>\n",
       "      <td>[TlH2+]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX327</td>\n",
       "      <td>[Cr+3]</td>\n",
       "      <td>[Cr+3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX9688</td>\n",
       "      <td>[Fe+2]</td>\n",
       "      <td>[Fe+2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX340</td>\n",
       "      <td>[Co+2]</td>\n",
       "      <td>[Co+2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX11521</td>\n",
       "      <td>[PbH2+2]</td>\n",
       "      <td>[PbH2+2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX622</td>\n",
       "      <td>[Fe+3]</td>\n",
       "      <td>[Fe+3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX20449</td>\n",
       "      <td>[Cu+2]</td>\n",
       "      <td>[Cu+2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOX226</td>\n",
       "      <td>[Cd+2]</td>\n",
       "      <td>[Cd+2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX1351</td>\n",
       "      <td>[SnH2+2]</td>\n",
       "      <td>[SnH2+2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX7279</td>\n",
       "      <td>[Mn+2]</td>\n",
       "      <td>[Mn+2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX4603</td>\n",
       "      <td>[Be+2]</td>\n",
       "      <td>[Be+2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX1461</td>\n",
       "      <td>[Zn+2]</td>\n",
       "      <td>[Zn+2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5942</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX14903</td>\n",
       "      <td>[Br-].[Na+]</td>\n",
       "      <td>[Br-].[Na+]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX235</td>\n",
       "      <td>[Ca+2].[Cl-].[Cl-]</td>\n",
       "      <td>[Ca+2].[Cl-].[Cl-]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX9283</td>\n",
       "      <td>[SbH6+3]</td>\n",
       "      <td>[SbH6+3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6717</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX928</td>\n",
       "      <td>[Ni+2]</td>\n",
       "      <td>[Ni+2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7407</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOX21126</td>\n",
       "      <td>N#C[Fe-2](C#N)(C#N)(C#N)(C#N)N=O</td>\n",
       "      <td>N#C[Fe-2](C#N)(C#N)(C#N)(C#N)N=O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      NR-AR  NR-AR-LBD  NR-AhR  NR-Aromatase  NR-ER  NR-ER-LBD  NR-PPAR-gamma  \\\n",
       "95      0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "255     0.0        1.0     1.0           NaN    NaN        1.0            1.0   \n",
       "659     0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "985     0.0        0.0     0.0           1.0    0.0        0.0            NaN   \n",
       "1423    0.0        0.0     0.0           NaN    0.0        0.0            0.0   \n",
       "1534    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "1722    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "1933    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "2147    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "2251    0.0        NaN     0.0           0.0    NaN        0.0            0.0   \n",
       "2760    0.0        NaN     1.0           NaN    0.0        NaN            NaN   \n",
       "2832    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "4024    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "4375    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "4611    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "5942    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "6477    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "6547    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "6717    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "7407    0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
       "\n",
       "      SR-ARE  SR-ATAD5  SR-HSE  SR-MMP  SR-p53    mol_id  \\\n",
       "95       0.0       0.0     0.0     0.0     0.0  TOX14836   \n",
       "255      NaN       NaN     1.0     NaN     1.0    TOX811   \n",
       "659      0.0       0.0     0.0     1.0     0.0    TOX131   \n",
       "985      0.0       0.0     0.0     0.0     NaN   TOX4331   \n",
       "1423     0.0       0.0     0.0     0.0     0.0    TOX327   \n",
       "1534     NaN       0.0     0.0     0.0     0.0   TOX9688   \n",
       "1722     1.0       0.0     0.0     0.0     0.0    TOX340   \n",
       "1933     1.0       0.0     0.0     0.0     0.0  TOX11521   \n",
       "2147     0.0       0.0     0.0     0.0     0.0    TOX622   \n",
       "2251     NaN       0.0     1.0     NaN     0.0  TOX20449   \n",
       "2760     NaN       1.0     1.0     0.0     NaN    TOX226   \n",
       "2832     0.0       0.0     0.0     0.0     0.0   TOX1351   \n",
       "4024     1.0       NaN     0.0     0.0     0.0   TOX7279   \n",
       "4375     0.0       0.0     0.0     NaN     0.0   TOX4603   \n",
       "4611     0.0       0.0     0.0     0.0     0.0   TOX1461   \n",
       "5942     0.0       0.0     0.0     0.0     0.0  TOX14903   \n",
       "6477     0.0       0.0     0.0     0.0     0.0    TOX235   \n",
       "6547     0.0       0.0     0.0     NaN     0.0   TOX9283   \n",
       "6717     0.0       0.0     0.0     NaN     0.0    TOX928   \n",
       "7407     1.0       0.0     0.0     0.0     0.0  TOX21126   \n",
       "\n",
       "                                smiles                       cano_smiles  \n",
       "95                           [I-].[K+]                         [I-].[K+]  \n",
       "255                             [Hg+2]                            [Hg+2]  \n",
       "659                             [Ba+2]                            [Ba+2]  \n",
       "985                            [TlH2+]                           [TlH2+]  \n",
       "1423                            [Cr+3]                            [Cr+3]  \n",
       "1534                            [Fe+2]                            [Fe+2]  \n",
       "1722                            [Co+2]                            [Co+2]  \n",
       "1933                          [PbH2+2]                          [PbH2+2]  \n",
       "2147                            [Fe+3]                            [Fe+3]  \n",
       "2251                            [Cu+2]                            [Cu+2]  \n",
       "2760                            [Cd+2]                            [Cd+2]  \n",
       "2832                          [SnH2+2]                          [SnH2+2]  \n",
       "4024                            [Mn+2]                            [Mn+2]  \n",
       "4375                            [Be+2]                            [Be+2]  \n",
       "4611                            [Zn+2]                            [Zn+2]  \n",
       "5942                       [Br-].[Na+]                       [Br-].[Na+]  \n",
       "6477                [Ca+2].[Cl-].[Cl-]                [Ca+2].[Cl-].[Cl-]  \n",
       "6547                          [SbH6+3]                          [SbH6+3]  \n",
       "6717                            [Ni+2]                            [Ni+2]  \n",
       "7407  N#C[Fe-2](C#N)(C#N)(C#N)(C#N)N=O  N#C[Fe-2](C#N)(C#N)(C#N)(C#N)N=O  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = get_smiles_dicts(smilesList)\n",
    "\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = remained_df[remained_df[task] == 0][[\"smiles\",task]]\n",
    "    positive_df = remained_df[remained_df[task] == 1][[\"smiles\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "\n",
    "test_df = remained_df.sample(frac=1/10, random_state=random_seed) # test set\n",
    "training_data = remained_df.drop(test_df.index) # training data\n",
    "\n",
    "# training data is further divided into validation set and train set\n",
    "valid_df = training_data.sample(frac=1/9, random_state=random_seed) # validation set\n",
    "train_df = training_data.drop(valid_df.index) # train set\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150028\n",
      "atom_fc.weight torch.Size([200, 39])\n",
      "atom_fc.bias torch.Size([200])\n",
      "neighbor_fc.weight torch.Size([200, 49])\n",
      "neighbor_fc.bias torch.Size([200])\n",
      "GRUCell.0.weight_ih torch.Size([600, 200])\n",
      "GRUCell.0.weight_hh torch.Size([600, 200])\n",
      "GRUCell.0.bias_ih torch.Size([600])\n",
      "GRUCell.0.bias_hh torch.Size([600])\n",
      "GRUCell.1.weight_ih torch.Size([600, 200])\n",
      "GRUCell.1.weight_hh torch.Size([600, 200])\n",
      "GRUCell.1.bias_ih torch.Size([600])\n",
      "GRUCell.1.bias_hh torch.Size([600])\n",
      "GRUCell.2.weight_ih torch.Size([600, 200])\n",
      "GRUCell.2.weight_hh torch.Size([600, 200])\n",
      "GRUCell.2.bias_ih torch.Size([600])\n",
      "GRUCell.2.bias_hh torch.Size([600])\n",
      "align.0.weight torch.Size([1, 400])\n",
      "align.0.bias torch.Size([1])\n",
      "align.1.weight torch.Size([1, 400])\n",
      "align.1.bias torch.Size([1])\n",
      "align.2.weight torch.Size([1, 400])\n",
      "align.2.bias torch.Size([1])\n",
      "attend.0.weight torch.Size([200, 200])\n",
      "attend.0.bias torch.Size([200])\n",
      "attend.1.weight torch.Size([200, 200])\n",
      "attend.1.bias torch.Size([200])\n",
      "attend.2.weight torch.Size([200, 200])\n",
      "attend.2.bias torch.Size([200])\n",
      "mol_GRUCell.weight_ih torch.Size([600, 200])\n",
      "mol_GRUCell.weight_hh torch.Size([600, 200])\n",
      "mol_GRUCell.bias_ih torch.Size([600])\n",
      "mol_GRUCell.bias_hh torch.Size([600])\n",
      "mol_align.weight torch.Size([1, 400])\n",
      "mol_align.bias torch.Size([1])\n",
      "mol_attend.weight torch.Size([200, 200])\n",
      "mol_attend.bias torch.Size([200])\n",
      "output.weight torch.Size([24, 200])\n",
      "output.bias torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([smilesList[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight),reduction='mean') for weight in weights]\n",
    "model = Fingerprint(radius, T, num_atom_features,num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where(y_val != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, eval_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[eval_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "                \n",
    "    eval_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "\n",
    "    eval_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return eval_roc, eval_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2133/1100950197.py:55: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:\t0\n",
      "train_roc_mean:0.46521449432674356\n",
      "valid_roc_mean:0.47224042387881804\n",
      "\n",
      "EPOCH:\t1\n",
      "train_roc_mean:0.6708733377828279\n",
      "valid_roc_mean:0.6986582511018339\n",
      "\n",
      "EPOCH:\t2\n",
      "train_roc_mean:0.7312592584466925\n",
      "valid_roc_mean:0.7375288231774704\n",
      "\n",
      "EPOCH:\t3\n",
      "train_roc_mean:0.7440610685126671\n",
      "valid_roc_mean:0.7488116044527798\n",
      "\n",
      "EPOCH:\t4\n",
      "train_roc_mean:0.7502063293540862\n",
      "valid_roc_mean:0.7510089968598926\n",
      "\n",
      "EPOCH:\t5\n",
      "train_roc_mean:0.7623413923737665\n",
      "valid_roc_mean:0.7627072319486031\n",
      "\n",
      "EPOCH:\t6\n",
      "train_roc_mean:0.7736175275795887\n",
      "valid_roc_mean:0.7717541401222902\n",
      "\n",
      "EPOCH:\t7\n",
      "train_roc_mean:0.7825854463084925\n",
      "valid_roc_mean:0.7802728738293755\n",
      "\n",
      "EPOCH:\t8\n",
      "train_roc_mean:0.8025054628612835\n",
      "valid_roc_mean:0.786657770084053\n",
      "\n",
      "EPOCH:\t9\n",
      "train_roc_mean:0.8037785773207586\n",
      "valid_roc_mean:0.7887406354708458\n",
      "\n",
      "EPOCH:\t10\n",
      "train_roc_mean:0.8196306191914974\n",
      "valid_roc_mean:0.8011716609149383\n",
      "\n",
      "EPOCH:\t11\n",
      "train_roc_mean:0.8269448391200059\n",
      "valid_roc_mean:0.8021143424394306\n",
      "\n",
      "EPOCH:\t12\n",
      "train_roc_mean:0.8339957046371514\n",
      "valid_roc_mean:0.8077384631847383\n",
      "\n",
      "EPOCH:\t13\n",
      "train_roc_mean:0.8386645453729117\n",
      "valid_roc_mean:0.8117298760896761\n",
      "\n",
      "EPOCH:\t14\n",
      "train_roc_mean:0.8434748466423384\n",
      "valid_roc_mean:0.8177548549666492\n",
      "\n",
      "EPOCH:\t15\n",
      "train_roc_mean:0.8473386359401771\n",
      "valid_roc_mean:0.8207957242464263\n",
      "\n",
      "EPOCH:\t16\n",
      "train_roc_mean:0.8495672305619587\n",
      "valid_roc_mean:0.8212477845860463\n",
      "\n",
      "EPOCH:\t17\n",
      "train_roc_mean:0.8521693915446925\n",
      "valid_roc_mean:0.8259320707599769\n",
      "\n",
      "EPOCH:\t18\n",
      "train_roc_mean:0.8531824601342676\n",
      "valid_roc_mean:0.8257387601081797\n",
      "\n",
      "EPOCH:\t19\n",
      "train_roc_mean:0.8551689208833145\n",
      "valid_roc_mean:0.8251521645761558\n",
      "\n",
      "EPOCH:\t20\n",
      "train_roc_mean:0.8593244601403218\n",
      "valid_roc_mean:0.8271860987143684\n",
      "\n",
      "EPOCH:\t21\n",
      "train_roc_mean:0.8630451642806264\n",
      "valid_roc_mean:0.8284782598684499\n",
      "\n",
      "EPOCH:\t22\n",
      "train_roc_mean:0.8660774164783208\n",
      "valid_roc_mean:0.8279231442898447\n",
      "\n",
      "EPOCH:\t23\n",
      "train_roc_mean:0.8650815634008849\n",
      "valid_roc_mean:0.8314349612309001\n",
      "\n",
      "EPOCH:\t24\n",
      "train_roc_mean:0.8691374338867014\n",
      "valid_roc_mean:0.829499178594145\n",
      "\n",
      "EPOCH:\t25\n",
      "train_roc_mean:0.8674143937102605\n",
      "valid_roc_mean:0.8259384693108482\n",
      "\n",
      "EPOCH:\t26\n",
      "train_roc_mean:0.8706682481944293\n",
      "valid_roc_mean:0.8248348984775458\n",
      "\n",
      "EPOCH:\t27\n",
      "train_roc_mean:0.8743160081224101\n",
      "valid_roc_mean:0.8317838090297308\n",
      "\n",
      "EPOCH:\t28\n",
      "train_roc_mean:0.8765426010370811\n",
      "valid_roc_mean:0.8310325632864047\n",
      "\n",
      "EPOCH:\t29\n",
      "train_roc_mean:0.8796533426602787\n",
      "valid_roc_mean:0.8319043927494093\n",
      "\n",
      "EPOCH:\t30\n",
      "train_roc_mean:0.8809971486659977\n",
      "valid_roc_mean:0.8301144301663604\n",
      "\n",
      "EPOCH:\t31\n",
      "train_roc_mean:0.8778098441627313\n",
      "valid_roc_mean:0.824124202875861\n",
      "\n",
      "EPOCH:\t32\n",
      "train_roc_mean:0.8841236334856917\n",
      "valid_roc_mean:0.8318903712101825\n",
      "\n",
      "EPOCH:\t33\n",
      "train_roc_mean:0.8846084072451803\n",
      "valid_roc_mean:0.8330212474901669\n",
      "\n",
      "EPOCH:\t34\n",
      "train_roc_mean:0.8890658181646093\n",
      "valid_roc_mean:0.8329143396699665\n",
      "\n",
      "EPOCH:\t35\n",
      "train_roc_mean:0.8870287806132531\n",
      "valid_roc_mean:0.8288149277380948\n",
      "\n",
      "EPOCH:\t36\n",
      "train_roc_mean:0.8890877600451593\n",
      "valid_roc_mean:0.8336190099555254\n",
      "\n",
      "EPOCH:\t37\n",
      "train_roc_mean:0.8924837322726124\n",
      "valid_roc_mean:0.8322334834508963\n",
      "\n",
      "EPOCH:\t38\n",
      "train_roc_mean:0.8912776974423874\n",
      "valid_roc_mean:0.8259864586270153\n",
      "\n",
      "EPOCH:\t39\n",
      "train_roc_mean:0.8922396588244993\n",
      "valid_roc_mean:0.8337385404532601\n",
      "\n",
      "EPOCH:\t40\n",
      "train_roc_mean:0.896393226794741\n",
      "valid_roc_mean:0.827614249410091\n",
      "\n",
      "EPOCH:\t41\n",
      "train_roc_mean:0.8994571126249441\n",
      "valid_roc_mean:0.8331949367409249\n",
      "\n",
      "EPOCH:\t42\n",
      "train_roc_mean:0.8982649538345454\n",
      "valid_roc_mean:0.8289763031145942\n",
      "\n",
      "EPOCH:\t43\n",
      "train_roc_mean:0.9005873043503362\n",
      "valid_roc_mean:0.8364527602905127\n",
      "\n",
      "EPOCH:\t44\n",
      "train_roc_mean:0.9017309566903319\n",
      "valid_roc_mean:0.8250959860354411\n",
      "\n",
      "EPOCH:\t45\n",
      "train_roc_mean:0.9056191647937757\n",
      "valid_roc_mean:0.8339980262514431\n",
      "\n",
      "EPOCH:\t46\n",
      "train_roc_mean:0.9081050844503192\n",
      "valid_roc_mean:0.8323543986220847\n",
      "\n",
      "EPOCH:\t47\n",
      "train_roc_mean:0.9074226225687646\n",
      "valid_roc_mean:0.830771750253923\n",
      "\n",
      "EPOCH:\t48\n",
      "train_roc_mean:0.9106391806986366\n",
      "valid_roc_mean:0.8331308457799992\n",
      "\n",
      "EPOCH:\t49\n",
      "train_roc_mean:0.9128958371150047\n",
      "valid_roc_mean:0.8280060933355076\n",
      "\n",
      "EPOCH:\t50\n",
      "train_roc_mean:0.911396661553647\n",
      "valid_roc_mean:0.8287942570311849\n",
      "\n",
      "EPOCH:\t51\n",
      "train_roc_mean:0.9165959730734013\n",
      "valid_roc_mean:0.8330891791218056\n",
      "\n",
      "EPOCH:\t52\n",
      "train_roc_mean:0.916623855682639\n",
      "valid_roc_mean:0.8296543663004569\n",
      "\n",
      "EPOCH:\t53\n",
      "train_roc_mean:0.9184067843963447\n",
      "valid_roc_mean:0.8296020170211458\n",
      "\n",
      "EPOCH:\t54\n",
      "train_roc_mean:0.9187426036885596\n",
      "valid_roc_mean:0.8291616243480443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_param ={}\n",
    "best_param[\"roc_epoch\"] = 0\n",
    "best_param[\"loss_epoch\"] = 0\n",
    "best_param[\"valid_roc\"] = 0\n",
    "best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    train_roc, train_loss = eval(model, train_df)\n",
    "    valid_roc, valid_loss = eval(model, valid_df)\n",
    "    train_roc_mean = np.array(train_roc).mean()\n",
    "    valid_roc_mean = np.array(valid_roc).mean()\n",
    "\n",
    "    if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "        best_param[\"roc_epoch\"] = epoch\n",
    "        best_param[\"valid_roc\"] = valid_roc_mean\n",
    "        if valid_roc_mean > 0.85:\n",
    "             torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')             \n",
    "    if valid_loss < best_param[\"valid_loss\"]:\n",
    "        best_param[\"loss_epoch\"] = epoch\n",
    "        best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "    print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "        +\"train_roc_mean\"+\":\"+str(train_roc_mean)+'\\n'\\\n",
    "        +\"valid_roc_mean\"+\":\"+str(valid_roc_mean)+'\\n'\\\n",
    "        )\n",
    "    if (epoch - best_param[\"roc_epoch\"] >10) and (epoch - best_param[\"loss_epoch\"] >20):        \n",
    "        break\n",
    "        \n",
    "    train(model, train_df, optimizer, loss_function)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
