{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/__init__.py:747: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:431.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(8) # for reproduce\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import QED\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "/tmp/ipykernel_65897/3850144271.py:31: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of successfully processed smiles:  1427\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'sider'\n",
    "tasks = [\n",
    "'SIDER1','SIDER2','SIDER3','SIDER4','SIDER5','SIDER6','SIDER7','SIDER8','SIDER9','SIDER10','SIDER11','SIDER12','SIDER13','SIDER14','SIDER15','SIDER16','SIDER17','SIDER18','SIDER19','SIDER20','SIDER21','SIDER22','SIDER23','SIDER24','SIDER25','SIDER26','SIDER27'\n",
    "]\n",
    "raw_filename = \"../data/sider.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 68\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 800\n",
    "p_dropout = 0.5\n",
    "fingerprint_dim = 200\n",
    "\n",
    "radius = 3\n",
    "T = 3\n",
    "weight_decay = 3 # also known as l2_regularization_lambda\n",
    "learning_rate = 3.5\n",
    "per_task_output_units_num = 2 # for classification model with 2 classes\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[05:26:01] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIDER1</th>\n",
       "      <th>SIDER2</th>\n",
       "      <th>SIDER3</th>\n",
       "      <th>SIDER4</th>\n",
       "      <th>SIDER5</th>\n",
       "      <th>SIDER6</th>\n",
       "      <th>SIDER7</th>\n",
       "      <th>SIDER8</th>\n",
       "      <th>SIDER9</th>\n",
       "      <th>SIDER10</th>\n",
       "      <th>...</th>\n",
       "      <th>SIDER20</th>\n",
       "      <th>SIDER21</th>\n",
       "      <th>SIDER22</th>\n",
       "      <th>SIDER23</th>\n",
       "      <th>SIDER24</th>\n",
       "      <th>SIDER25</th>\n",
       "      <th>SIDER26</th>\n",
       "      <th>SIDER27</th>\n",
       "      <th>smiles</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CC[C@H](C)[C@H]1C(=O)N[C@H]2CSSC[C@@H](C(=O)N[...</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)CN)C(=O)N[C@H](C(=O)N[C@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CC[C@H](C)[C@@H](C(=O)N[C@@H](CCC(=O)O)C(=O)N[...</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@H]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CC[C@H](C)[C@@H](C(=O)N[C@@H](CC1=CC=C(C=C1)O)...</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)[C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CC1=CN(C(=O)NC1=O)[C@H]2C[C@@H]([C@H](O2)COP(=...</td>\n",
       "      <td>COCCO[C@@H]1[C@H](SP(=O)([O-])OC[C@H]2O[C@@H](...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CCC(C)C(C(=O)NC(CCC(=O)N)C(=O)NC(CC(C)C)C(=O)N...</td>\n",
       "      <td>CCC(C)C(NC(=O)C(CCC(=O)O)NC(=O)C(CO)NC(=O)C(NC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CC1C(=O)NC(C(=O)NC2CSSCC3C(=O)NC(C(=O)NC(C(=O)...</td>\n",
       "      <td>CSCCC1NC(=O)C(CC(C)C)NC(=O)C(CCCNC(=N)N)NC(=O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CC[C@H](C)[C@H]1C(=O)N[C@H](C(=O)NCC(=O)N[C@H]...</td>\n",
       "      <td>CC[C@H](C)[C@@H]1NC(=O)[C@@H]2CSSC[C@H](NC(=O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CC[C@H](C)[C@@H](C(=O)N1CCC[C@H]1C(=O)N[C@@H](...</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](CCC(=O)O)NC(=O)[C@...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SIDER1  SIDER2  SIDER3  SIDER4  SIDER5  SIDER6  SIDER7  SIDER8  SIDER9  \\\n",
       "5          0       1       0       1       1       1       1       0       1   \n",
       "29         1       1       0       1       1       1       1       1       1   \n",
       "41         0       1       0       0       1       0       0       0       0   \n",
       "47         0       0       0       0       1       0       1       0       1   \n",
       "50         0       0       0       1       1       1       1       0       1   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "1391       1       0       0       0       1       1       1       0       1   \n",
       "1392       0       1       0       0       1       1       1       0       1   \n",
       "1393       0       1       0       1       1       1       1       1       1   \n",
       "1396       0       1       0       0       1       1       1       0       1   \n",
       "1397       0       0       1       1       1       1       1       0       1   \n",
       "\n",
       "      SIDER10  ...  SIDER20  SIDER21  SIDER22  SIDER23  SIDER24  SIDER25  \\\n",
       "5           0  ...        1        1        1        0        0        1   \n",
       "29          0  ...        1        1        1        0        1        1   \n",
       "41          0  ...        0        0        0        0        0        0   \n",
       "47          0  ...        0        0        0        0        0        0   \n",
       "50          1  ...        1        1        0        0        0        1   \n",
       "...       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "1391        0  ...        0        1        1        0        0        1   \n",
       "1392        0  ...        1        1        1        0        1        1   \n",
       "1393        0  ...        1        1        1        0        1        1   \n",
       "1396        0  ...        1        1        1        0        0        0   \n",
       "1397        1  ...        1        1        1        0        1        1   \n",
       "\n",
       "      SIDER26  SIDER27                                             smiles  \\\n",
       "5           1        1  CC[C@H](C)[C@H]1C(=O)N[C@H]2CSSC[C@@H](C(=O)N[...   \n",
       "29          1        1  CC[C@H](C)[C@@H](C(=O)N[C@@H](CCC(=O)O)C(=O)N[...   \n",
       "41          0        0                                                  N   \n",
       "47          1        1  CC[C@H](C)[C@@H](C(=O)N[C@@H](CC1=CC=C(C=C1)O)...   \n",
       "50          1        1                                                  I   \n",
       "...       ...      ...                                                ...   \n",
       "1391        1        0  CC1=CN(C(=O)NC1=O)[C@H]2C[C@@H]([C@H](O2)COP(=...   \n",
       "1392        1        1  CCC(C)C(C(=O)NC(CCC(=O)N)C(=O)NC(CC(C)C)C(=O)N...   \n",
       "1393        1        1  CC1C(=O)NC(C(=O)NC2CSSCC3C(=O)NC(C(=O)NC(C(=O)...   \n",
       "1396        1        1  CC[C@H](C)[C@H]1C(=O)N[C@H](C(=O)NCC(=O)N[C@H]...   \n",
       "1397        1        1  CC[C@H](C)[C@@H](C(=O)N1CCC[C@H]1C(=O)N[C@@H](...   \n",
       "\n",
       "                                            cano_smiles  \n",
       "5     CC[C@H](C)[C@H](NC(=O)CN)C(=O)N[C@H](C(=O)N[C@...  \n",
       "29    CC[C@H](C)[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@H]...  \n",
       "41                                                    N  \n",
       "47    CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)[C...  \n",
       "50                                                    I  \n",
       "...                                                 ...  \n",
       "1391  COCCO[C@@H]1[C@H](SP(=O)([O-])OC[C@H]2O[C@@H](...  \n",
       "1392  CCC(C)C(NC(=O)C(CCC(=O)O)NC(=O)C(CO)NC(=O)C(NC...  \n",
       "1393  CSCCC1NC(=O)C(CC(C)C)NC(=O)C(CCCNC(=N)N)NC(=O)...  \n",
       "1396  CC[C@H](C)[C@@H]1NC(=O)[C@@H]2CSSC[C@H](NC(=O)...  \n",
       "1397  CC[C@H](C)[C@H](NC(=O)[C@H](CCC(=O)O)NC(=O)[C@...  \n",
       "\n",
       "[61 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smilesList = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())<151]\n",
    "\n",
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = remained_df[remained_df[task] == 0][[\"smiles\",task]]\n",
    "    positive_df = remained_df[remained_df[task] == 1][[\"smiles\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "\n",
    "test_df = remained_df.sample(frac=1/10, random_state=3) # test set\n",
    "training_data = remained_df.drop(test_df.index) # training data\n",
    "\n",
    "# training data is further divided into validation set and train set\n",
    "valid_df = training_data.sample(frac=1/9, random_state=3) # validation set\n",
    "train_df = training_data.drop(valid_df.index) # train set\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1156058\n",
      "atom_fc.weight torch.Size([200, 39])\n",
      "atom_fc.bias torch.Size([200])\n",
      "neighbor_fc.weight torch.Size([200, 49])\n",
      "neighbor_fc.bias torch.Size([200])\n",
      "GRUCell.0.weight_ih torch.Size([600, 200])\n",
      "GRUCell.0.weight_hh torch.Size([600, 200])\n",
      "GRUCell.0.bias_ih torch.Size([600])\n",
      "GRUCell.0.bias_hh torch.Size([600])\n",
      "GRUCell.1.weight_ih torch.Size([600, 200])\n",
      "GRUCell.1.weight_hh torch.Size([600, 200])\n",
      "GRUCell.1.bias_ih torch.Size([600])\n",
      "GRUCell.1.bias_hh torch.Size([600])\n",
      "GRUCell.2.weight_ih torch.Size([600, 200])\n",
      "GRUCell.2.weight_hh torch.Size([600, 200])\n",
      "GRUCell.2.bias_ih torch.Size([600])\n",
      "GRUCell.2.bias_hh torch.Size([600])\n",
      "align.0.weight torch.Size([1, 400])\n",
      "align.0.bias torch.Size([1])\n",
      "align.1.weight torch.Size([1, 400])\n",
      "align.1.bias torch.Size([1])\n",
      "align.2.weight torch.Size([1, 400])\n",
      "align.2.bias torch.Size([1])\n",
      "attend.0.weight torch.Size([200, 200])\n",
      "attend.0.bias torch.Size([200])\n",
      "attend.1.weight torch.Size([200, 200])\n",
      "attend.1.bias torch.Size([200])\n",
      "attend.2.weight torch.Size([200, 200])\n",
      "attend.2.bias torch.Size([200])\n",
      "mol_GRUCell.weight_ih torch.Size([600, 200])\n",
      "mol_GRUCell.weight_hh torch.Size([600, 200])\n",
      "mol_GRUCell.bias_ih torch.Size([600])\n",
      "mol_GRUCell.bias_hh torch.Size([600])\n",
      "mol_align.weight torch.Size([1, 400])\n",
      "mol_align.bias torch.Size([1])\n",
      "mol_attend.weight torch.Size([200, 200])\n",
      "mol_attend.bias torch.Size([200])\n",
      "output.weight torch.Size([54, 200])\n",
      "output.bias torch.Size([54])\n"
     ]
    }
   ],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([canonical_smiles_list[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight),reduction='mean') for weight in weights]\n",
    "model = Fingerprint(radius, T, num_atom_features,num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "model.cuda()\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "#         print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where(y_val != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, eval_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[eval_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "                \n",
    "    eval_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "\n",
    "    eval_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return eval_roc, eval_loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65897/1100950197.py:55: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:\t0\n",
      "train_roc_mean:0.5013257983300141\n",
      "valid_roc_mean:0.5034681350123162\n",
      "\n",
      "EPOCH:\t1\n",
      "train_roc_mean:0.5543366787595173\n",
      "valid_roc_mean:0.5328603303217478\n",
      "\n",
      "EPOCH:\t2\n",
      "train_roc_mean:0.5642245769133652\n",
      "valid_roc_mean:0.5261042760974386\n",
      "\n",
      "EPOCH:\t3\n",
      "train_roc_mean:0.576267537922496\n",
      "valid_roc_mean:0.5357537691230827\n",
      "\n",
      "EPOCH:\t4\n",
      "train_roc_mean:0.583845757122824\n",
      "valid_roc_mean:0.5355388331808116\n",
      "\n",
      "EPOCH:\t5\n",
      "train_roc_mean:0.5880795334700147\n",
      "valid_roc_mean:0.5482308162409555\n",
      "\n",
      "EPOCH:\t6\n",
      "train_roc_mean:0.589011591824554\n",
      "valid_roc_mean:0.5579235834948016\n",
      "\n",
      "EPOCH:\t7\n",
      "train_roc_mean:0.5940559516073137\n",
      "valid_roc_mean:0.5597053583753607\n",
      "\n",
      "EPOCH:\t8\n",
      "train_roc_mean:0.5940525132687974\n",
      "valid_roc_mean:0.5646171256503449\n",
      "\n",
      "EPOCH:\t9\n",
      "train_roc_mean:0.5962548102300639\n",
      "valid_roc_mean:0.5663339912779034\n",
      "\n",
      "EPOCH:\t10\n",
      "train_roc_mean:0.5993740586082568\n",
      "valid_roc_mean:0.5572249437588925\n",
      "\n",
      "EPOCH:\t11\n",
      "train_roc_mean:0.602381546078106\n",
      "valid_roc_mean:0.5624493212163183\n",
      "\n",
      "EPOCH:\t12\n",
      "train_roc_mean:0.607436140787396\n",
      "valid_roc_mean:0.5471159731010107\n",
      "\n",
      "EPOCH:\t13\n",
      "train_roc_mean:0.6109326078513091\n",
      "valid_roc_mean:0.5521410374284998\n",
      "\n",
      "EPOCH:\t14\n",
      "train_roc_mean:0.6141228653990102\n",
      "valid_roc_mean:0.5571517082085007\n",
      "\n",
      "EPOCH:\t15\n",
      "train_roc_mean:0.6210638555117385\n",
      "valid_roc_mean:0.5495683479825403\n",
      "\n",
      "EPOCH:\t16\n",
      "train_roc_mean:0.6247511426218126\n",
      "valid_roc_mean:0.5493919659117092\n",
      "\n",
      "EPOCH:\t17\n",
      "train_roc_mean:0.6294004777226363\n",
      "valid_roc_mean:0.5486843211225475\n",
      "\n",
      "EPOCH:\t18\n",
      "train_roc_mean:0.6367845794071458\n",
      "valid_roc_mean:0.549134716811518\n",
      "\n",
      "EPOCH:\t19\n",
      "train_roc_mean:0.6414763685860883\n",
      "valid_roc_mean:0.5422635565999884\n",
      "\n",
      "EPOCH:\t20\n",
      "train_roc_mean:0.6508658005250749\n",
      "valid_roc_mean:0.5458568579345555\n",
      "\n",
      "EPOCH:\t21\n",
      "train_roc_mean:0.6572695530832037\n",
      "valid_roc_mean:0.5515381191311298\n",
      "\n",
      "EPOCH:\t22\n",
      "train_roc_mean:0.6612956635115661\n",
      "valid_roc_mean:0.5462040734904039\n",
      "\n",
      "EPOCH:\t23\n",
      "train_roc_mean:0.6657643069323077\n",
      "valid_roc_mean:0.5486022915379501\n",
      "\n",
      "EPOCH:\t24\n",
      "train_roc_mean:0.662855080672332\n",
      "valid_roc_mean:0.5376972463073156\n",
      "\n",
      "EPOCH:\t25\n",
      "train_roc_mean:0.6649919743057539\n",
      "valid_roc_mean:0.5480476030258696\n",
      "\n",
      "EPOCH:\t26\n",
      "train_roc_mean:0.672389136066471\n",
      "valid_roc_mean:0.5478511516033631\n",
      "\n",
      "EPOCH:\t27\n",
      "train_roc_mean:0.675562651141442\n",
      "valid_roc_mean:0.5489796748377914\n",
      "\n",
      "EPOCH:\t28\n",
      "train_roc_mean:0.6792069420461044\n",
      "valid_roc_mean:0.5530963584440505\n",
      "\n",
      "EPOCH:\t29\n",
      "train_roc_mean:0.6775563435848979\n",
      "valid_roc_mean:0.5575391730096546\n",
      "\n",
      "EPOCH:\t30\n",
      "train_roc_mean:0.6851151625622862\n",
      "valid_roc_mean:0.5510691021258817\n",
      "\n",
      "EPOCH:\t31\n",
      "train_roc_mean:0.687646896887513\n",
      "valid_roc_mean:0.5524556857740728\n",
      "\n",
      "EPOCH:\t32\n",
      "train_roc_mean:0.6915586248447937\n",
      "valid_roc_mean:0.5522921462790976\n",
      "\n",
      "EPOCH:\t33\n",
      "train_roc_mean:0.6942510801933091\n",
      "valid_roc_mean:0.5528464901784511\n",
      "\n",
      "EPOCH:\t34\n",
      "train_roc_mean:0.6970090947628754\n",
      "valid_roc_mean:0.5581357852677042\n",
      "\n",
      "EPOCH:\t35\n",
      "train_roc_mean:0.69900287772184\n",
      "valid_roc_mean:0.5572963340708584\n",
      "\n",
      "EPOCH:\t36\n",
      "train_roc_mean:0.7001573888750724\n",
      "valid_roc_mean:0.5494790233699977\n",
      "\n",
      "EPOCH:\t37\n",
      "train_roc_mean:0.7015211040826583\n",
      "valid_roc_mean:0.5670544426097843\n",
      "\n",
      "EPOCH:\t38\n",
      "train_roc_mean:0.7031463231728473\n",
      "valid_roc_mean:0.5576480391474147\n",
      "\n",
      "EPOCH:\t39\n",
      "train_roc_mean:0.7064483815140654\n",
      "valid_roc_mean:0.5576180906152688\n",
      "\n",
      "EPOCH:\t40\n",
      "train_roc_mean:0.7104379234408665\n",
      "valid_roc_mean:0.5607499953438988\n",
      "\n",
      "EPOCH:\t41\n",
      "train_roc_mean:0.7125940062361672\n",
      "valid_roc_mean:0.5625933369887608\n",
      "\n",
      "EPOCH:\t42\n",
      "train_roc_mean:0.7143225687869967\n",
      "valid_roc_mean:0.5696488801949195\n",
      "\n",
      "EPOCH:\t43\n",
      "train_roc_mean:0.7171177383382271\n",
      "valid_roc_mean:0.5596491359428327\n",
      "\n",
      "EPOCH:\t44\n",
      "train_roc_mean:0.7197208629008611\n",
      "valid_roc_mean:0.5578324454440934\n",
      "\n",
      "EPOCH:\t45\n",
      "train_roc_mean:0.7188624643141013\n",
      "valid_roc_mean:0.563123438016975\n",
      "\n",
      "EPOCH:\t46\n",
      "train_roc_mean:0.7224130659219915\n",
      "valid_roc_mean:0.5727745089216785\n",
      "\n",
      "EPOCH:\t47\n",
      "train_roc_mean:0.7268589558929157\n",
      "valid_roc_mean:0.5666117104408056\n",
      "\n",
      "EPOCH:\t48\n",
      "train_roc_mean:0.7291975500556127\n",
      "valid_roc_mean:0.5623704223405854\n",
      "\n",
      "EPOCH:\t49\n",
      "train_roc_mean:0.7307023684022155\n",
      "valid_roc_mean:0.5695327967881022\n",
      "\n",
      "EPOCH:\t50\n",
      "train_roc_mean:0.7328915124964924\n",
      "valid_roc_mean:0.5865067110077411\n",
      "\n",
      "EPOCH:\t51\n",
      "train_roc_mean:0.7357924753005457\n",
      "valid_roc_mean:0.5666983261038389\n",
      "\n",
      "EPOCH:\t52\n",
      "train_roc_mean:0.7386967068017093\n",
      "valid_roc_mean:0.5810093362361679\n",
      "\n",
      "EPOCH:\t53\n",
      "train_roc_mean:0.7374380018210489\n",
      "valid_roc_mean:0.5670593797735156\n",
      "\n",
      "EPOCH:\t54\n",
      "train_roc_mean:0.7425853419658948\n",
      "valid_roc_mean:0.577095833417226\n",
      "\n",
      "EPOCH:\t55\n",
      "train_roc_mean:0.7427528793680109\n",
      "valid_roc_mean:0.577314524269745\n",
      "\n",
      "EPOCH:\t56\n",
      "train_roc_mean:0.7450873987602721\n",
      "valid_roc_mean:0.5836843197613877\n",
      "\n",
      "EPOCH:\t57\n",
      "train_roc_mean:0.7503639780777924\n",
      "valid_roc_mean:0.5791376169076449\n",
      "\n",
      "EPOCH:\t58\n",
      "train_roc_mean:0.7548249228788948\n",
      "valid_roc_mean:0.5843111331475478\n",
      "\n",
      "EPOCH:\t59\n",
      "train_roc_mean:0.7536780258134639\n",
      "valid_roc_mean:0.5772475738680216\n",
      "\n",
      "EPOCH:\t60\n",
      "train_roc_mean:0.7571823945618085\n",
      "valid_roc_mean:0.5800142835924101\n",
      "\n",
      "EPOCH:\t61\n",
      "train_roc_mean:0.7618520081434701\n",
      "valid_roc_mean:0.5867770026855853\n",
      "\n",
      "EPOCH:\t62\n",
      "train_roc_mean:0.7606163079920478\n",
      "valid_roc_mean:0.5809417229769069\n",
      "\n",
      "EPOCH:\t63\n",
      "train_roc_mean:0.7627036638523981\n",
      "valid_roc_mean:0.5904728603356396\n",
      "\n",
      "EPOCH:\t64\n",
      "train_roc_mean:0.7613461288809616\n",
      "valid_roc_mean:0.5823475069877309\n",
      "\n",
      "EPOCH:\t65\n",
      "train_roc_mean:0.7664922937895213\n",
      "valid_roc_mean:0.5868129898408392\n",
      "\n",
      "EPOCH:\t66\n",
      "train_roc_mean:0.7687302413493292\n",
      "valid_roc_mean:0.5904241296667173\n",
      "\n",
      "EPOCH:\t67\n",
      "train_roc_mean:0.7734252046745878\n",
      "valid_roc_mean:0.5873763232274307\n",
      "\n",
      "EPOCH:\t68\n",
      "train_roc_mean:0.7740508049033098\n",
      "valid_roc_mean:0.5964451245366823\n",
      "\n",
      "EPOCH:\t69\n",
      "train_roc_mean:0.7800608467891822\n",
      "valid_roc_mean:0.5919745909877624\n",
      "\n",
      "EPOCH:\t70\n",
      "train_roc_mean:0.7821004178933672\n",
      "valid_roc_mean:0.5957767564534259\n",
      "\n",
      "EPOCH:\t71\n",
      "train_roc_mean:0.777425216066459\n",
      "valid_roc_mean:0.5825597064762017\n",
      "\n",
      "EPOCH:\t72\n",
      "train_roc_mean:0.7836832405449582\n",
      "valid_roc_mean:0.5938336964297494\n",
      "\n",
      "EPOCH:\t73\n",
      "train_roc_mean:0.786834040835261\n",
      "valid_roc_mean:0.5850994921015276\n",
      "\n",
      "EPOCH:\t74\n",
      "train_roc_mean:0.7830466422068221\n",
      "valid_roc_mean:0.6027314644140865\n",
      "\n",
      "EPOCH:\t75\n",
      "train_roc_mean:0.7890471738338968\n",
      "valid_roc_mean:0.5975455698220487\n",
      "\n",
      "EPOCH:\t76\n",
      "train_roc_mean:0.7918850359376973\n",
      "valid_roc_mean:0.6003281690750824\n",
      "\n",
      "EPOCH:\t77\n",
      "train_roc_mean:0.7963564832845355\n",
      "valid_roc_mean:0.5846218006624296\n",
      "\n",
      "EPOCH:\t78\n",
      "train_roc_mean:0.7975874550609987\n",
      "valid_roc_mean:0.5976704878788917\n",
      "\n",
      "EPOCH:\t79\n",
      "train_roc_mean:0.7971319391027569\n",
      "valid_roc_mean:0.5869450341784586\n",
      "\n",
      "EPOCH:\t80\n",
      "train_roc_mean:0.7992423557250362\n",
      "valid_roc_mean:0.6049093097128784\n",
      "\n",
      "EPOCH:\t81\n",
      "train_roc_mean:0.7998893434288749\n",
      "valid_roc_mean:0.6083840453273481\n",
      "\n",
      "EPOCH:\t82\n",
      "train_roc_mean:0.8028127771961048\n",
      "valid_roc_mean:0.5951212312223596\n",
      "\n",
      "EPOCH:\t83\n",
      "train_roc_mean:0.8079283500819301\n",
      "valid_roc_mean:0.5977666347139967\n",
      "\n",
      "EPOCH:\t84\n",
      "train_roc_mean:0.8115924352728079\n",
      "valid_roc_mean:0.6006777447582148\n",
      "\n",
      "EPOCH:\t85\n",
      "train_roc_mean:0.8140592834905865\n",
      "valid_roc_mean:0.6057279031148811\n",
      "\n",
      "EPOCH:\t86\n",
      "train_roc_mean:0.8166964279814505\n",
      "valid_roc_mean:0.5961852858365458\n",
      "\n",
      "EPOCH:\t87\n",
      "train_roc_mean:0.8178596935563908\n",
      "valid_roc_mean:0.6048019023625263\n",
      "\n",
      "EPOCH:\t88\n",
      "train_roc_mean:0.819383041624784\n",
      "valid_roc_mean:0.6116164110531267\n",
      "\n",
      "EPOCH:\t89\n",
      "train_roc_mean:0.824162541854188\n",
      "valid_roc_mean:0.6027709794037494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_param ={}\n",
    "best_param[\"roc_epoch\"] = 0\n",
    "best_param[\"loss_epoch\"] = 0\n",
    "best_param[\"valid_roc\"] = 0\n",
    "best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    train_roc, train_loss = eval(model, train_df)\n",
    "    valid_roc, valid_loss = eval(model, valid_df)\n",
    "    train_roc_mean = np.array(train_roc).mean()\n",
    "    valid_roc_mean = np.array(valid_roc).mean()\n",
    "\n",
    "    if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "        best_param[\"roc_epoch\"] = epoch\n",
    "        best_param[\"valid_roc\"] = valid_roc_mean\n",
    "        if valid_roc_mean > 0.62:\n",
    "             torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')             \n",
    "    if valid_loss < best_param[\"valid_loss\"]:\n",
    "        best_param[\"loss_epoch\"] = epoch\n",
    "        best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "    print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "        +\"train_roc_mean\"+\":\"+str(train_roc_mean)+'\\n'\\\n",
    "        +\"valid_roc_mean\"+\":\"+str(valid_roc_mean)+'\\n'\\\n",
    "        )\n",
    "    if (epoch - best_param[\"roc_epoch\"] >18) and (epoch - best_param[\"loss_epoch\"] >28):        \n",
    "        break\n",
    "        \n",
    "    train(model, train_df, optimizer, loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "\n",
    "best_model_dict = best_model.state_dict()\n",
    "best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "(best_model.align[0].weight == model.align[0].weight).all()\n",
    "test_roc, test_losses = eval(model, test_df)\n",
    "\n",
    "print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "      +\"\\n\"+\"test_roc:\"+str(test_roc)\n",
    "      +\"\\n\"+\"test_roc_mean:\",str(np.array(test_roc).mean())\n",
    "     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
